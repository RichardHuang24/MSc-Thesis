# MSc-Thesis

This repository contains the code for the MSc Thesis Report:  
**"Illuminating Prompt Space for Discovering Creativity in LLMs with MAP-Elites."**

The project applies the **MAP-Elites algorithm** to systematically explore and discover diverse, high-performing prompts that enhance the creative problem-solving abilities of Large Language Models (LLMs).

---

## Framework Overview

The experiment is structured into three phases:

1. **Preparation**  
2. **Evolutionary Search**  
3. **Analysis**  

At the heart of the framework is the **MAP-Elites algorithm**, guided by a multi-objective fitness function and a **UMAP-defined behavioral space**.

---

## Key Features

- **Evolutionary Prompt Search**  
  MAP-Elites discovers a diverse archive of high-quality prompts, mapping the relationship between prompt "behavior" and performance.  

- **Context-Free Grammar (CFG)**  
  Prompts are generated by combining components like roles, reasoning strategies, and creativity cues.  

- **Multi-Objective Creativity Evaluation**  
  - *Convergent Creativity*: quality, safety, and feasibility, scored by an Evaluator LLM.  
  - *Divergent Creativity*: novelty and diversity, quantified via semantic entropy.  

- **Behavioral Characterization with UMAP**  
  UMAP creates a 2D map of prompt embeddings, serving as the descriptor grid for MAP-Elites.  

- **Creative Problem-Solving Dataset**  
  The **MacGyver dataset** is used, containing unconventional, resource-constrained problems designed to elicit creativity.  

---

## Prerequisites and Installation

### Requirements
- Python 3.8+  
- Hugging Face account and API key  

### Installation

git clone <your-repository-url>
cd <your-repository-directory>
pip install numpy pandas pyyaml requests tqdm umap-learn scikit-learn matplotlib seaborn

---

### Configuration (config.py)

Before running experiments, set your Hugging Face API key and endpoints in `config.py`.

# IMPORTANT: Replace with your actual key
HF_API_KEY = "hf_YourHuggingFaceApiKeyHere"

# URLs to your deployed private endpoints
GENERATOR_LLM_ENDPOINT = "https://<your-generator-endpoint>.aws.endpoints.huggingface.cloud"
EVALUATOR_LLM_ENDPOINT = "https://<your-evaluator-endpoint>.aws.endpoints.huggingface.cloud"
EMBEDDING_LLM_ENDPOINT = "https://<your-embedding-endpoint>.aws.endpoints.huggingface.cloud"
NLI_MODEL_ENDPOINT = "https://<your-nli-endpoint>.aws.endpoints.huggingface.cloud"

---

## Experimental Workflow

The main entry script is `run_experiment.py`.

### Step 1: Prepare UMAP Model
Train the UMAP model (one-time setup):

python run_experiment.py prepare-umap

Generates `trained_umap_model.pkl` in `results/`.

---

### Step 2: Run Baseline Experiments

**Baseline 1: No Prompt**

python main.py baseline_no_prompt --problem-id 351
python main.py baseline_no_prompt

**Baseline 2: Random Prompt**

python main.py baseline_random_prompt --problem-id 351
python main.py baseline_random_prompt

Results saved in `results/baseline_experiments/`.

---

### Step 3: Run MAP-Elites Experiment

Run on a specific problem:

python run_experiment.py run-me --problem-id 351

Run on randomly selected problems:

python run_experiment.py run-me

Results stored in `results/`.

---

### Step 4: Analyze Results

**MAP-Elites Analysis**

python analysis_map.py

Outputs plots and reports to `analysis_map/`.

**Baseline Comparison**

python analysis_baseline.py

Outputs comparison plots to `analysis_baseline/`.

---

## Results & Analysis

- **Archive Growth**: MAP-Elites shows fast early archive expansion, then plateaus as niches fill.  
- **Behavioral Diversity**: Solutions spread across UMAP space, showing well-separated families of prompts.  
- **Cluster Performance**: Some clusters specialize in high convergent scores, others in divergent creativity, demonstrating controllable trade-offs.  
- **Heatmaps & Examples**: Component-level analysis shows which roles, creativity cues, and formats yield the most effective creative problem-solving.  


